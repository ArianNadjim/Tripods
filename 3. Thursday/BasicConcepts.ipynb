{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Basic Probability Concepts for Random Variables \n",
    "Brief Description:  \n",
    "1) Random variables of normal distribution and Bernoulli distribution will be studied;  \n",
    "2) The probability concepts include mean, variance, $L^p$ norm ($p < \\infty$), $L^{\\infty}$ norm, covariance;  \n",
    "3) The built-in functions in numpy will be called if they exist. In addition, all the probability concepts will be defined explicitly for illustrations;  \n",
    "4) Sample statistic will be used as an estimation for the corresponding probablity concept. The accuracy will be quantified, which lies in the theory of statistical inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages that will be used in the file:\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact, fixed\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33126559  0.68056907  2.03949393  1.98999521  1.73138665  1.12727195\n",
      "  0.54415507 -0.55228519  0.67355508  1.30311385  0.34066929 -0.07904808\n",
      " -0.71717002 -1.32876725  0.96243664 -0.29030662  1.61562318 -0.53453993\n",
      "  0.28285365  0.41913051 -1.12760017  0.10984453 -0.22996114  0.36926766\n",
      " -0.80095877 -1.5429744   0.88040779 -1.09301201 -0.56515724  1.86194542\n",
      "  0.26544394 -1.14931284 -0.30573409 -0.44125493 -0.13982374 -0.20638593\n",
      "  0.29724608  0.29281036 -0.36518581 -0.67327054 -0.48347802  0.99678373\n",
      "  0.03517132 -0.64628359 -0.20005689 -0.22329234  0.39064985  0.75064237\n",
      " -0.28468031  0.25748069]\n"
     ]
    }
   ],
   "source": [
    "#Draw 50 samples from a random variable of normal distribution with mean = 0 and standard deviation = 1:\n",
    "sample_normal = np.random.normal(0,1,50)\n",
    "print(sample_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Implement basic probability concepts for samples drawn from the standard normal distribution using numpy functions (mean and variance):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X$ denote a random varible. Mean of the random varible is defined as follows.  \n",
    "Definition of mean:  \n",
    "$\\mathbb{E}X := \\int_{\\Omega} X(\\omega) dP(\\omega) $, where $P$ represents the probability measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13137347126850668"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute sample mean of sample_normal using numpy:\n",
    "np.mean(sample_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Question 1.1.1: \n",
    "\n",
    "###### (a) Why is it reasonable to use sample mean for the estimation of the mean of the random variable? (Hint: Law of large numbers (VB, Theorem 1.3.1). More precisely, let N:= sample size, then the sample could be viewed as a realization of N independent random variables of the standard normal distribution).\n",
    "##### (b) Intuitively, the larger number of samples, the more accurate the sample mean is as an estimation for the mean of the given random variable. Can you quantify the \"accuracy\"? For example, assume that the given random variable has variance bounded by 2, how many samples are needed for the estimation error to be within 0.01 with probability 0.9? (Hint: Chebyshev's inequality / VB, Corollary 1.2.5.)\n",
    "##### (c) Is the bound provided by Chebyshev's inequality sharp? In other words, does there exist a better way to control the error so that the sample size can be smaller to obtain the estimation of comparable accuracy? (Hint: if X and Y are independent random variables of normal distribution, what is the distribution of X+Y? )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference: Graphic Illustration of Chebyshev's inequality (VB, Corollary 1.2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danny\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the t specified in the corollary\n",
    "t = 3\n",
    "\n",
    "# Set the random variable X and generate 100000 samples of it\n",
    "# We use normal distribution as an example, can change it to different distribution but need to specify the mu and sigma\n",
    "mu = 2\n",
    "sigma = 1\n",
    "X = np.random.normal(loc = mu, scale = sigma, size = 100000)\n",
    "\n",
    "# We will demonstrate the inequality by directly compute the right hand side and approximate the left hand side by 100000 samples\n",
    "# We will also vary t so see how the relationship change as t changes\n",
    "\n",
    "# Initialize the collection of LHS and RHS as we change t\n",
    "LHS = []\n",
    "RHS = []\n",
    "\n",
    "# Define the range of t we want to change, can modify it to generate different plots\n",
    "t_range = np.arange(0, 10, 0.1)\n",
    "\n",
    "# iterate over all the t in t_range\n",
    "for t in t_range:\n",
    "    # once we specify t, we sample 100000 X as defined above\n",
    "    X = np.random.normal(loc = mu, scale = sigma, size = 100000)\n",
    "    # We approximate the LHS by calculating the portion of the sample that match the condition\n",
    "    LHS.append(np.sum(np.abs(X - mu) >= t) / len(X))\n",
    "    # We calculate the RHS directly\n",
    "    RHS.append(sigma ** 2 / t ** 2)\n",
    "\n",
    "# plot the resulting RHS and LHS as we vary t\n",
    "plt.figure()\n",
    "plt.ylim(0, 1)\n",
    "plt.plot(t_range, LHS, label = \"LHS\")\n",
    "plt.plot(t_range, RHS, label = \"RHS\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of variance:  \n",
    "Var$(X):= \\mathbb{E}(X - \\mathbb{E}X)^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75037793697739097"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute sample variance of sample_normal using numpy:\n",
    "np.var(sample_normal, ddof = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.1.2: What does \"ddof\" value represent for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Implement basic probability concepts for samples drawn from the standard normal distribution using self-defined functions (mean, variance, L^p norm, L^infinty norm, covariance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute sample mean of a sample:\n",
    "def mean(ar):\n",
    "    return np.sum(ar)/len(ar)\n",
    "\n",
    "#Compute sample variance of a sample:\n",
    "def variance(ar):\n",
    "    mean = np.sum(ar)/len(ar)\n",
    "    ar_demean = ar-mean\n",
    "    ar_demean_squared = np.square(ar_demean)\n",
    "    return np.sum(ar_demean_squared)/(len(ar)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.2.1: To compute the sample variance, why is the denominator in the last step is (the number of the sample - 1), instead of (the number of the sample)? (Hint: Bessel correction.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please mimic the definitions of functions for mean and variance and define functions for $L^p$ ($p < \\infty$ ) norm and $L^\\infty$ norm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of $L^p$ norm:   \n",
    "$\\|X \\|_{L^p} := (\\mathbb{E}|X|^p)^{\\frac{1}{p}}$\n",
    "\n",
    "Definition of $L^{\\infty}$ norm:  \n",
    "$\\|X \\|_{L^{\\infty}} := ess \\sup|X|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code goes here:\n",
    "#Compute L^p norm of a sample:\n",
    "def L_p(ar,p):\n",
    "    ar_abs_power_p = np.power(np.abs(ar),p)\n",
    "    return (np.sum(ar_abs_power_p)/len(ar))**(1/p)\n",
    "\n",
    "#Compute L^infinity norm of a sample:\n",
    "def L_infinity(ar):\n",
    "    ar_abs = np.abs(ar)\n",
    "    return np.max(ar_abs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of covariance of two random variables $X$ and $Y$:   \n",
    "$cov(X,Y):= \\mathbb{E}((X-\\mathbb{E}X)(Y-\\mathbb{E}Y))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute covariance of two input samples:\n",
    "def cov(x,y):\n",
    "    if len(x) == len(y):\n",
    "        mean_x = np.mean(x)\n",
    "        mean_y = np.mean(y)\n",
    "        return np.sum((x - mean_x)*(y-mean_y))/(len(x)-1)\n",
    "    else:\n",
    "        print('There is an issue of missing data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.2.2: \n",
    "##### (a) Why is the denominator in the last step is (the number of the sample - 1), instead of (the number of the sample)?\n",
    "##### (b) When the issue of \"missing data\" occurs, what could be a plausible solution?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please call the self-defined functions and compare the results with the ones you obtain by calling the built-in function in numpy for sample_normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.131373471269\n",
      "0.750377936977\n",
      "0.992956195158\n",
      "2.03949392914\n",
      "-0.0563367866223\n"
     ]
    }
   ],
   "source": [
    "#Your codes goes here:\n",
    "#Use the self-defined function to compute sample mean:\n",
    "print(mean(sample_normal))\n",
    "#Use the self-defined function to compute sample variance:\n",
    "print(variance(sample_normal))\n",
    "#Use the self-defined function to compute L^3 norm of the sample:\n",
    "print(L_p(sample_normal-mean(sample_normal),3))\n",
    "#Use the self-defined function to compute L^infinity norm of the sample:\n",
    "print(L_infinity(sample_normal))\n",
    "#Use the self-defined function to compute the covariance of two samples:\n",
    "sample_1 = sample_normal[1:11]\n",
    "sample_2 = sample_normal[11:21]\n",
    "print(cov(sample_1,sample_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bernoulli Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 0 0 0 0 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Draw 50 samples from a random variable of Bernoulli distribution taking values 1 and -1 with probablity 1/2:\n",
    "sample_bernoulli = np.random.binomial(1,1/2,50)\n",
    "print(sample_bernoulli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Implement basic probability concepts for samples drawn from the Bernoulli distribution using numpy functions (mean and variance):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please call the built-in functions in numpy (for mean and variance) to compute the sample mean and sample variance for the sample_bernoulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.255102040816\n"
     ]
    }
   ],
   "source": [
    "# Your codes goes here:\n",
    "#Compute sample mean of sample_bernoulli using numpy:\n",
    "print(np.mean(sample_bernoulli))\n",
    "#Compute sample variance of sample_bernoulli using numpy and self_defined function:\n",
    "print(np.var(sample_bernoulli,ddof = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.1.1: \n",
    "##### (a) Can you quantify the accuracy of the sample mean as estimations for the mean of the random variable in this case? Does the same estimate in Question 1.1.1 (b) hold? Hint: One can invoke Chebyshev's inequality as in Question 1.1.1(b). \n",
    "##### (b) In the current setting, one does not know the exact distribution of the sum of the Bernoulli random variables as in Question 1.1.1. (c). However, one might recall the central limit theorem (VB, Theorem 1.3.2) and hope to approximate the distribution for the sum of the Bernoulli random variables by a normal distribution. Is this possible to render an exponential decay (of the estimation error) in the sample size? (Hint: What is the convergence rate of the central limit theorem?) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Reference: Graphic Illustration of the central limit theorem (VB, Theorem 1.3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: If the below graph can't be displayed correctly, run the following code in command line\n",
    "# pip install ipywidgets\n",
    "# pip install jupyter_contrib_nbextensions && jupyter contrib nbextension install\n",
    "# jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e441a2727034442dba1dc7add4d9b3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='alpha', max=1.0), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.CLT(alpha, X)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function that take the power alpha and a set of sample X with dimension n times m. n represents the number of samples\n",
    "# and m represent the size of each sample\n",
    "def CLT(alpha, X):  \n",
    "    # plot the distribution with regard to alpha using sns.distplot()\n",
    "    sns.distplot(np.sum(X, axis = 1) / (X.shape[1] ** alpha))\n",
    "    #x = np.linspace(mu - 1 * np.sqrt(mu), mu + 1 * np.sqrt(mu))\n",
    "    \n",
    "    # also plot the normal distribution it should converge to \n",
    "    #plt.plot(x, stats.norm.pdf(x, mu, np.sqrt(mu) / np.sqrt(k)))\n",
    "    \n",
    "# can change the range of k and drag the bar to see the change \n",
    "X = np.random.poisson(lam = 4, size = (10000, 10))\n",
    "interact(CLT, alpha = (0, 1, 0.1), X = fixed(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that take the power alpha and a set of sample X with dimension n times m. n represents the number of samples\n",
    "# and m represent the size of each sample\n",
    "def CLT(alpha, X):  \n",
    "    # sum all the number in each sample\n",
    "    #your codes go in here\n",
    "    \n",
    "    # divide by sample size to the power of alpha, (be careful on whether to divide by m or n)\n",
    "    #your codes go in here\n",
    "    \n",
    "    # plot the distribution with regard to alpha using sns.distplot(). If you are unfamiliar with the function, google the API for sns\n",
    "    #your codes go in here\n",
    "\n",
    "#initialize the X, can change to what ever distribution and whatever size\n",
    "X = np.random.poisson(lam = 4, size = (10000, 10))\n",
    "    \n",
    "# can change the range of k and drag the bar to see the change, no need to change this\n",
    "interact(CLT, alpha = (0, 1, 0.1), X = fixed(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference: Graphic Illustration of the convergence rate in the central limit theorem (VB, Theorem 2.1.3 Berry-Esseen central limit theorem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002624612740131371\n",
      "0.2992414861559882\n"
     ]
    }
   ],
   "source": [
    "# We will use poission distribution as an example, can change to other distribution but need to change corresponding mu and sigma\n",
    "mu = 3\n",
    "sigma = np.sqrt(mu)\n",
    "\n",
    "# N is the size of the sample. Both N and t can change\n",
    "N = 30\n",
    "t = 0.5\n",
    "Zn = (np.mean(np.random.poisson(lam = mu, size = (10000, N)), axis = 1) - mu) / sigma * np.sqrt(N)\n",
    "rho = np.mean(np.abs((np.random.poisson(lam = mu, size = 1000000) - mu) ** 3)) / sigma ** 3\n",
    "\n",
    "# calculate the resulting LHS and RHS, probability is estimated by 1000000 sample\n",
    "RHSP = np.sum(Zn >= t) / len(Zn)\n",
    "LHSP = 1 - norm.cdf(t)\n",
    "RHS = rho / np.sqrt(N)\n",
    "\n",
    "# Print the two sides, see the relationship\n",
    "print(np.abs(LHSP - RHSP))\n",
    "print(RHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99c4c443c884e82aeeea4f08357458c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='t', max=3.0, min=-3.0), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.CLT_diff(t)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can vary t by dragging the bar, essentially convert above lines to a function\n",
    "def CLT_diff(t):\n",
    "    LHS_list = []\n",
    "    RHS_list = []\n",
    "    # vary N from 2 to 50000 with step size 100, for each N and the given t, we calculate the RHS and the LHS\n",
    "    for N in range(2, 5000, 100):\n",
    "        Zn = (np.mean(np.random.poisson(lam = mu, size = (1000, N)), axis = 1) - mu) / sigma * np.sqrt(N)\n",
    "        rho = np.mean(np.abs((np.random.poisson(lam = mu, size = 10000) - mu) ** 3)) / sigma ** 3\n",
    "        RHSP = np.sum(Zn >= t) / len(Zn)\n",
    "        LHSP = 1 - norm.cdf(t)\n",
    "        RHS = rho / np.sqrt(N)\n",
    "        LHS_list.append(np.abs(LHSP - RHSP))\n",
    "        RHS_list.append(RHS)\n",
    "    # After we get the result for each N, we plot the result\n",
    "    plt.plot(range(2, 5000, 100), LHS_list, label = \"LHS\")\n",
    "    plt.plot(range(2, 5000, 100), RHS_list, label = \"RHS\")\n",
    "    plt.xlabel(\"N\")\n",
    "    plt.legend()\n",
    "\n",
    "# Now can drag the bar and vary t to see how the RHS and LHS changes\n",
    "interact(CLT_diff, t = (-3,3 , 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2.1.1 Continued:\n",
    "##### (c) Is the bound provided by Chebyshev's inequality sharp? Is there any better estimate available in this case? (Hint: Hoeffding’s inequality / VB, Theorem 2.2.2 and Theorem 2.2.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Implement basic probability concepts for samples drawn from the standard normal distribution using self-defined functions (mean, variance, $L^p (p < \\infty)$ norm, $L^{\\infty}$ norm, covariance):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please call the self-defined functions and compare the results with the ones you obtain by calling the built-in function in numpy for sample_bernoulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.255102040816\n",
      "1.14260754336\n",
      "1\n",
      "-0.0497076023392\n"
     ]
    }
   ],
   "source": [
    "# Your code goes here:\n",
    "#Use the self-defined function to compute mean of the sample:\n",
    "print(mean(sample_bernoulli))\n",
    "#Use the self-defined function to compute variance of the sample:\n",
    "print(variance(sample_bernoulli))\n",
    "#Use the self-defined function to compute L^4 norm of the sample:\n",
    "print(L_p(sample_normal-mean(sample_bernoulli),4))\n",
    "#Use the self-defined function to compute L^infinity norm of the sample:\n",
    "print(L_infinity(sample_bernoulli))\n",
    "#Use the self-defined function to compute the covariance of two samples:\n",
    "sample_1 = sample_bernoulli[1:20]\n",
    "sample_2 = sample_bernoulli[21:40]\n",
    "print(cov(sample_1,sample_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
